import os
import argparse
import torch
import pandas as pd
import numpy as np
import cv2
from tqdm import tqdm
from sklearn.metrics import jaccard_score, f1_score
from mednextv1.MedNextV1 import MedNeXt
import torch.nn as nn
from scipy.ndimage import binary_fill_holes

def parse_args():
    parser = argparse.ArgumentParser(description="Test MedNeXt for segmentation")
    parser.add_argument("--image_root", type=str, required=True, help="å›¾åƒæ ¹ç›®å½•")
    parser.add_argument("--mask_root", type=str, required=True, help="æ©ç æ ¹ç›®å½•")
    parser.add_argument("--excel_dir", type=str, required=True, help="äº”æŠ˜Excelç›®å½•")
    parser.add_argument("--weights_dir", type=str, required=True, help="MedNeXt æƒé‡ç›®å½•ï¼ŒåŒ…å« mednext_fold{n}.pth")
    parser.add_argument("--image_size", type=int, default=256, help="è¾“å…¥å°ºå¯¸")
    parser.add_argument("--in_channels", type=int, default=1, help="è¾“å…¥é€šé“æ•°")
    parser.add_argument("--num_classes", type=int, default=2, help="ç±»åˆ«æ•°")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡ï¼Œå¦‚ cuda:0 æˆ– cpu")
    parser.add_argument("--fold_start", type=int, default=1, help="å¼€å§‹æŠ˜ï¼ˆå«ï¼‰")
    parser.add_argument("--fold_end", type=int, default=5, help="ç»“æŸæŠ˜ï¼ˆå«ï¼‰")
    parser.add_argument("--vis_samples", type=int, default=10, help="å¯è§†åŒ–æŠ½æ ·æ•°é‡")
    parser.add_argument("--output_dir", type=str, default="visual_comparison", help="å¯è§†åŒ–è¾“å‡ºç›®å½•")
    return parser.parse_args()

def ensure_dir(path):
    if path:
        os.makedirs(path, exist_ok=True)

# åå¤„ç†ï¼šä¿ç•™æœ€å¤§è¿é€šåŸŸå¹¶å¡«å……ç©ºæ´
def post_process_mask(mask_np: np.ndarray) -> np.ndarray:
    if mask_np.ndim != 2:
        raise ValueError(f"Expected 2D mask but got shape {mask_np.shape}")
    mask_np = mask_np.astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_np, connectivity=8)
    if num_labels <= 1:
        return np.zeros_like(mask_np)
    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
    largest_component = (labels == largest_label).astype(np.uint8)
    filled_mask = binary_fill_holes(largest_component).astype(np.uint8)
    return filled_mask

# åŠ è½½æ¨¡å‹
def load_model(model_path, args, device):
    model = MedNeXt(
        in_channels=args.in_channels,
        n_channels=32,
        n_classes=args.num_classes,
        exp_r=2,
        kernel_size=3,
        deep_supervision=True,
        do_res=False,
        do_res_up_down=True,
        block_counts=[2, 2, 2, 2, 2, 2, 2, 2, 2]
    ).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    return model

# å¯è§†åŒ–å åŠ å‡½æ•°
def overlay_mask(image_gray, mask, color=(0, 255, 0)):
    image_color = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)
    overlay = image_color.copy()
    overlay[mask == 1] = color
    combined = cv2.addWeighted(image_color, 0.7, overlay, 0.3, 0)
    return combined

# å•æŠ˜è¯„ä¼°
def evaluate_fold(fold, args, device):
    print(f"\nğŸ” æ­£åœ¨è¯„ä¼° Fold {fold}...")
    output_compare_dir = os.path.join(args.output_dir, f"fold{fold}")
    ensure_dir(output_compare_dir)

    val_df = pd.read_excel(os.path.join(args.excel_dir, f"fold{fold}_test.xlsx"))
    model = load_model(os.path.join(args.weights_dir, f"mednext_fold{fold}.pth"), args, device)
    vis_df = val_df.sample(n=min(args.vis_samples, len(val_df)), random_state=fold * 100).reset_index(drop=True) if args.vis_samples > 0 else pd.DataFrame()

    all_preds, all_targets = [], []

    # å¯è§†åŒ–æ ·æœ¬ï¼ˆæ ¹æ®å‚æ•°æŠ½æ ·ï¼Œå·²åœ¨ä¸Šæ–¹ç”Ÿæˆ vis_dfï¼‰

    for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=f"Fold {fold} Testing"):
        uid = str(row["æ£€æŸ¥æµæ°´å·"])

        image_dir = os.path.join(args.image_root, uid)
        mask_dir = os.path.join(args.mask_root, uid)

        image_file = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        mask_file = [f for f in os.listdir(mask_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        if not image_file or not mask_file:
            print(f"âš ï¸ è­¦å‘Š: {uid} å›¾åƒæˆ–æ©è†œæ–‡ä»¶ç¼ºå¤±")
            continue

        image_path = os.path.join(image_dir, image_file[0])
        mask_path = os.path.join(mask_dir, mask_file[0])

        image_raw = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        mask_raw = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if image_raw is None or mask_raw is None:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {uid}")
            continue

        image_resized = cv2.resize(image_raw, (args.image_size, args.image_size))
        image_tensor = torch.tensor(image_resized, dtype=torch.float32, device=device) / 255.0
        image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)  # 1 x 1 x H x W

        with torch.no_grad():
            outputs = model(image_tensor)
            output = outputs[-1] if isinstance(outputs, list) else outputs
            output = nn.functional.interpolate(output, size=(args.image_size, args.image_size), mode='bilinear', align_corners=False)
            pred = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

        # åå¤„ç†
        pred = post_process_mask(pred)

        mask_resized = cv2.resize(mask_raw, (args.image_size, args.image_size))
        target = (mask_resized > 127).astype(np.int64)

        all_preds.extend(pred.flatten())
        all_targets.extend(target.flatten())

        if args.vis_samples > 0 and not vis_df.empty and uid in vis_df["æ£€æŸ¥æµæ°´å·"].astype(str).values:
            vis_pred = overlay_mask(image_resized, pred, color=(0, 0, 255))    # çº¢è‰²é¢„æµ‹
            vis_target = overlay_mask(image_resized, target, color=(0, 255, 0))  # ç»¿è‰²çœŸå®
            combined = np.hstack([
                cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR),
                vis_pred,
                vis_target
            ])
            save_path = os.path.join(output_compare_dir, f"{uid}_compare.png")
            cv2.imwrite(save_path, combined)

    # å‰æ™¯ç±»åˆ«è¯„ä¼°
    miou = jaccard_score(all_targets, all_preds, labels=[1], average='macro')
    dice = f1_score(all_targets, all_preds, labels=[1], average='macro')

    print(f"âœ… Fold {fold} å‰æ™¯è¯„ä¼°")
    print(f"mIoU: {miou:.4f}")
    print(f"Dice: {dice:.4f}")
    print(f"å¯è§†åŒ–å›¾ä¿å­˜è·¯å¾„ï¼š{output_compare_dir}")

    return miou, dice

# å¤šæŠ˜æµ‹è¯•ï¼ˆå¦‚éœ€å¯æ”¹ rangeï¼‰
def test_all_folds(args):
    all_miou, all_dice = [], []
    device = torch.device(args.device if torch.cuda.is_available() or args.device == "cpu" else "cpu")
    for fold in range(args.fold_start, args.fold_end + 1):
        miou, dice = evaluate_fold(fold, args, device)
        all_miou.append(miou)
        all_dice.append(dice)

    print("\nğŸ“Š äº”æŠ˜å¹³å‡è¯„ä¼°ç»“æœï¼š")
    print(f"mIoU å¹³å‡å€¼: {np.mean(all_miou):.4f} Â± {np.std(all_miou):.4f}")
    print(f"Dice å¹³å‡å€¼: {np.mean(all_dice):.4f} Â± {np.std(all_dice):.4f}")


if __name__ == "__main__":
    args = parse_args()
    ensure_dir(args.output_dir)
    test_all_folds(args)
